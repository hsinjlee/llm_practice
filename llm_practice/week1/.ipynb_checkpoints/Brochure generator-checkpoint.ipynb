{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e793b2-6775-426a-a139-4848291d0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face ‚Äì The AI community building the future.\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Posts\n",
      "Docs\n",
      "Solutions\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "NEW\n",
      "Use Ollama with GGUF Models from the HF Hub\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "Collov-Labs/Monetico\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "1.56k\n",
      "‚Ä¢\n",
      "521\n",
      "microsoft/OmniParser\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "4.12k\n",
      "‚Ä¢\n",
      "926\n",
      "stabilityai/stable-diffusion-3.5-large\n",
      "Updated\n",
      "12 days ago\n",
      "‚Ä¢\n",
      "153k\n",
      "‚Ä¢\n",
      "979\n",
      "genmo/mochi-1-preview\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "807\n",
      "stabilityai/stable-diffusion-3.5-medium\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "16.7k\n",
      "‚Ä¢\n",
      "244\n",
      "Browse 400k+ models\n",
      "Spaces\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "433\n",
      "üìà\n",
      "IC Light V2\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "782\n",
      "üèÉ\n",
      "Stable Diffusion 3.5 Large\n",
      "Generate images with SD3.5\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "4.76k\n",
      "üëï\n",
      "Kolors Virtual Try-On\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "1.06k\n",
      "üó£Ô∏è\n",
      "F5-TTS\n",
      "F5-TTS & E2-TTS: Zero-Shot Voice Cloning (Unofficial Demo)\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "4.82k\n",
      "üñ•Ô∏è\n",
      "FLUX.1 [dev]\n",
      "Browse 150k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Sep 3\n",
      "‚Ä¢\n",
      "7.93k\n",
      "‚Ä¢\n",
      "6.1k\n",
      "neuralwork/arxiver\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "3.36k\n",
      "‚Ä¢\n",
      "318\n",
      "Spawning/PD12M\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "2.78k\n",
      "‚Ä¢\n",
      "61\n",
      "vikhyatk/lofi\n",
      "Updated\n",
      "8 days ago\n",
      "‚Ä¢\n",
      "2.35k\n",
      "‚Ä¢\n",
      "63\n",
      "BAAI/Infinity-MM\n",
      "Updated\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "31.5k\n",
      "‚Ä¢\n",
      "40\n",
      "Browse 100k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "‚Ä¢\n",
      "336 models\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "2034 models\n",
      "Amazon Web Services\n",
      "company\n",
      "‚Ä¢\n",
      "17 models\n",
      "Google\n",
      "company\n",
      "‚Ä¢\n",
      "868 models\n",
      "Intel\n",
      "company\n",
      "‚Ä¢\n",
      "208 models\n",
      "Microsoft\n",
      "company\n",
      "‚Ä¢\n",
      "337 models\n",
      "Grammarly\n",
      "company\n",
      "‚Ä¢\n",
      "10 models\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "13 models\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "134,338\n",
      "State-of-the-art ML for Pytorch, TensorFlow, and JAX.\n",
      "Diffusers\n",
      "25,995\n",
      "State-of-the-art diffusion models for image and audio generation in PyTorch.\n",
      "Safetensors\n",
      "2,860\n",
      "Simple, safe way to store and distribute neural networks weights safely and quickly.\n",
      "Hub Python Library\n",
      "2,092\n",
      "Client library for the HF Hub: manage repositories from your Python runtime.\n",
      "Tokenizers\n",
      "9,028\n",
      "Fast tokenizers, optimized for both research and production.\n",
      "PEFT\n",
      "16,293\n",
      "Parameter efficient finetuning methods for large models.\n",
      "Transformers.js\n",
      "11,818\n",
      "State-of-the-art Machine Learning for the web. Run Transformers directly in your browser, with no need for a server.\n",
      "timm\n",
      "32,096\n",
      "State-of-the-art computer vision models, layers, optimizers, training/evaluation, and utilities.\n",
      "TRL\n",
      "9,922\n",
      "Train transformer language models with reinforcement learning.\n",
      "Datasets\n",
      "19,217\n",
      "Access and share datasets for computer vision, audio, and NLP tasks.\n",
      "Text Generation Inference\n",
      "8,990\n",
      "Toolkit to serve Large Language Models.\n",
      "Accelerate\n",
      "7,896\n",
      "Easily train and use PyTorch models with multi-GPU, TPU, mixed-precision.\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Tasks\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out\n",
    "\n",
    "hf = Website(\"https://huggingface.co\")\n",
    "print(hf.title)\n",
    "print(hf.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Hugging Face Website Summary\\n\\nHugging Face is a collaborative platform centered on the machine learning community, offering a wide range of resources to build and share machine learning models, datasets, and applications. It serves as a hub for creators to explore and collaborate on over 400,000 models and 100,000 datasets across various modalities including text, image, video, audio, and 3D.\\n\\n## Key Features:\\n- **Models and Datasets**: Users can access and contribute to a vast library of machine learning models and datasets.\\n- **Spaces**: Interactive applications showcasing various models are available, with several running demos.\\n- **Open Source Tools**: Hugging Face provides an array of open-source libraries including Transformers, Diffusers, and Safetensors among others, supporting state-of-the-art ML applications.\\n- **Enterprise Solutions**: Paid compute and enterprise offerings allow organizations to deploy optimized inference endpoints and access advanced features suitable for secure and controlled environments.\\n\\n## Recent News:\\n- **New Feature**: Users can now utilize Ollama with GGUF models from the Hugging Face Hub, enhancing functionality within the platform.\\n  \\nThrough its community-driven approach, Hugging Face aims to accelerate machine learning advancements by providing tools and resources that foster collaboration and exploration in the AI field.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Summary\n",
       "\n",
       "The Hugging Face website serves as a collaborative platform dedicated to the machine learning community, focusing on models, datasets, and various applications. \n",
       "\n",
       "## Key Features\n",
       "- **Models:** Offers access to over 400,000 machine learning models, trending examples include:\n",
       "  - **Collov-Labs/Monetico** (1.56k updates)\n",
       "  - **microsoft/OmniParser** (4.12k updates)\n",
       "  - **stabilityai/stable-diffusion-3.5-large** (153k updates)\n",
       "\n",
       "- **Spaces:** This section allows users to run numerous applications, including those for image generation and voice cloning, with some popular examples listed:\n",
       "  - **Stable Diffusion 3.5 Large**\n",
       "  - **F5-TTS**\n",
       "\n",
       "- **Datasets:** Users can browse and utilize over 100,000 datasets tailored for various tasks; recent updates include:\n",
       "  - **fka/awesome-chatgpt-prompts** (7.93k updates)\n",
       "  - **BAAI/Infinity-MM** (31.5k updates)\n",
       "\n",
       "## New Announcement\n",
       "- **Use Ollama with GGUF Models:** Highlights recent improvements regarding model compatibility and usage.\n",
       "\n",
       "## Community Engagement\n",
       "- The platform encourages users to share their work and collaborate, aiming to build a robust machine learning portfolio and enhance collaborative tools.\n",
       "\n",
       "## Pricing\n",
       "- Offers a range of compute solutions starting at $0.60/hour for GPU, and enterprise solutions beginning at $20/user/month, indicating a focus on both individual and organizational needs in machine learning.\n",
       "\n",
       "Overall, Hugging Face positions itself as a central hub for machine learning practitioners to accelerate development, deployment, and collaboration in AI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of vLLM Website\n",
       "\n",
       "The vLLM website serves as the official documentation and resource hub for the vLLM library, which is designed for efficient and easy serving of large language models (LLMs). It emphasizes high-performance capabilities such as state-of-the-art serving throughput, efficient memory management, and support for various hardware platforms, including NVIDIA, AMD, and Intel.\n",
       "\n",
       "## Key Features:\n",
       "\n",
       "- **Fast and Efficient**: Implements PagedAttention for memory management and supports continuous batching for improved throughput.\n",
       "- **Flexible Deployment**: Compatible with popular APIs and various deployment options like Docker, Kubernetes, and multiple cloud services.\n",
       "- **Model Support**: Offers seamless integration with HuggingFace models and supports multiple quantization protocols.\n",
       "- **Community Engagement**: Hosts events like vLLM Meetups to foster community participation.\n",
       "\n",
       "## Documentation Highlights:\n",
       "\n",
       "- Installation guides for multiple platforms (ROCm, OpenVINO, CPU, etc.)\n",
       "- Quickstart tutorials and examples to help users get up and running quickly.\n",
       "- Detailed usage documentation for different deployment scenarios and model integrations.\n",
       "\n",
       "The website also links to external resources like a blog post introducing PagedAttention and a research paper discussing their throughput enhancements.\n",
       "\n",
       "For further information, users can explore the community-oriented features and follow updates related to the library‚Äôs development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://docs.vllm.ai/en/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eff74-55c4-4d4b-b267-703edbc293c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
